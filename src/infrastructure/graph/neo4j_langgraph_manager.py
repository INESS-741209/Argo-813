#!/usr/bin/env python3
"""
Neo4j LangGraph Integration Manager for ARGO System
ì‹¤ì œ ë°ì´í„°ë¡œ ì¸í•œ ì‹œìŠ¤í…œ íŒŒê´´ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•œ ê²¬ê³ í•œ ê·¸ë˜í”„ ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬
"""

import asyncio
import logging
import json
import uuid
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from enum import Enum
from neo4j import GraphDatabase
from neo4j.exceptions import ServiceUnavailable, TransientError, ConstraintError
# from langgraph.graph import StateGraph, END  # MockNeo4j ì‚¬ìš©ìœ¼ë¡œ ì œê±°
# from langgraph.prebuilt import ToolExecutor  # ìµœì‹  ë²„ì „ì—ì„œëŠ” ì‚¬ìš© ë¶ˆê°€
# from langgraph.checkpoint.memory import MemorySaver  # MockNeo4j ì‚¬ìš©ìœ¼ë¡œ ì œê±°
import redis

logger = logging.getLogger(__name__)

class GraphOperationType(Enum):
    CREATE_NODE = "create_node"
    UPDATE_NODE = "update_node"
    DELETE_NODE = "delete_node"
    CREATE_RELATIONSHIP = "create_relationship"
    UPDATE_RELATIONSHIP = "update_relationship"
    DELETE_RELATIONSHIP = "delete_relationship"
    MERGE_NODE = "merge_node"
    MERGE_RELATIONSHIP = "merge_relationship"
    BATCH_OPERATION = "batch_operation"

@dataclass
class GraphOperation:
    id: str
    operation_type: GraphOperationType
    target_type: str  # 'node' or 'relationship'
    target_id: Optional[str] = None
    labels: List[str] = field(default_factory=list)
    properties: Dict[str, Any] = field(default_factory=dict)
    relationship_type: Optional[str] = None
    start_node_id: Optional[str] = None
    end_node_id: Optional[str] = None
    constraints: List[str] = field(default_factory=list)
    validation_rules: List[str] = field(default_factory=list)
    timestamp: datetime = field(default_factory=datetime.utcnow)
    priority: int = 1  # 1: ë†’ìŒ, 2: ë³´í†µ, 3: ë‚®ìŒ

class Neo4jLangGraphManager:
    """
    Neo4jì™€ LangGraphë¥¼ í†µí•©í•œ ê³ ê¸‰ ê·¸ë˜í”„ ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ì
    ì‹¤ì œ ë°ì´í„°ë¡œ ì¸í•œ ì‹œìŠ¤í…œ íŒŒê´´ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•œ ê²¬ê³ í•œ ë©”ì»¤ë‹ˆì¦˜
    """
    
    def __init__(self, neo4j_config: Dict, redis_config: Dict = None):
        self.neo4j_config = neo4j_config
        self.redis_config = redis_config or {
            'host': 'localhost',
            'port': 6379,
            'db': 0
        }
        
        # Neo4j ì—°ê²°
        self.driver = self._get_neo4j_driver()
        
        # Redis ì—°ê²° (MockRedis ìë™ ì „í™˜ í¬í•¨)
        self.redis_client = self._get_redis_client()
        
        # LangGraph ìƒíƒœ ê·¸ë˜í”„ (MockNeo4j ì‚¬ìš©ìœ¼ë¡œ ì œê±°)
        # self.state_graph = self._create_state_graph()
        
        # ì‘ì—… í
        self.operation_queue: List[GraphOperation] = []
        self.failed_operations: List[GraphOperation] = []
        
        # ìŠ¤í‚¤ë§ˆ ë° ì œì•½ ì¡°ê±´
        self.node_constraints: Dict[str, List[str]] = {}
        self.relationship_constraints: Dict[str, List[str]] = {}
        self.indexes: Dict[str, List[str]] = {}
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self.query_stats: Dict[str, Dict] = {}
        self.performance_metrics: Dict[str, float] = {}
        
        # ì´ˆê¸°í™”
        self._initialize_schema()
        
        logger.info("Neo4jLangGraphManager initialized")
    
    def _get_neo4j_driver(self):
        """Neo4j ë“œë¼ì´ë²„ ìƒì„± (ì‹¤íŒ¨ ì‹œ MockNeo4jë¡œ ìë™ ì „í™˜)"""
        try:
            driver = GraphDatabase.driver(
                self.neo4j_config.get('uri', 'bolt://localhost:7687'),
                auth=(
                    self.neo4j_config.get('username', 'neo4j'),
                    self.neo4j_config.get('password', 'password')
                )
            )
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            with driver.session() as session:
                session.run("RETURN 1")
            logger.info("âœ… Neo4j ì—°ê²° ì„±ê³µ")
            return driver
        except Exception as e:
            logger.warning(f"âš ï¸ Neo4j ì—°ê²° ì‹¤íŒ¨, MockNeo4jë¡œ ì „í™˜: {e}")
            from src.infrastructure.mocks.mock_neo4j import create_mock_neo4j_driver
            return create_mock_neo4j_driver()
    
    def _get_redis_client(self) -> redis.Redis:
        """Redis í´ë¼ì´ì–¸íŠ¸ ìƒì„± (ì‹¤íŒ¨ ì‹œ MockRedisë¡œ ìë™ ì „í™˜)"""
        try:
            client = redis.Redis(
                host=self.redis_config.get('host', 'localhost'),
                port=self.redis_config.get('port', 6379),
                db=self.redis_config.get('db', 0),
                decode_responses=True,
                socket_connect_timeout=5,
                socket_timeout=5
            )
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            client.ping()
            logger.info("âœ… Redis ì—°ê²° ì„±ê³µ")
            return client
        except Exception as e:
            logger.warning(f"âš ï¸ Redis ì—°ê²° ì‹¤íŒ¨, MockRedisë¡œ ì „í™˜: {e}")
            from src.infrastructure.mocks.mock_redis import MockRedis
            return MockRedis()
    
    def _create_state_graph(self):
        """LangGraph ìƒíƒœ ê·¸ë˜í”„ ìƒì„± (MockNeo4j ì‚¬ìš©ìœ¼ë¡œ ì œê±°)"""
        logger.info("ğŸ”§ MockNeo4j ì‚¬ìš©ìœ¼ë¡œ LangGraph ìƒíƒœ ê·¸ë˜í”„ ìƒì„± ìƒëµ")
        return None
    
    async def _execute_create_operation(self, operation: GraphOperation) -> Dict[str, Any]:
        """ë…¸ë“œ ìƒì„± ì‘ì—… ì‹¤í–‰"""
        try:
            with self.driver.session() as session:
                # ë…¸ë“œ ìƒì„± ì¿¼ë¦¬
                query = f"""
                CREATE (n:{':'.join(operation.labels)} {{
                    id: $id,
                    {', '.join([f'{k}: ${k}' for k in operation.properties.keys()])}
                }})
                RETURN n
                """
                
                result = session.run(query, operation.properties)
                node = result.single()
                
                if node:
                    logger.info(f"âœ… ë…¸ë“œ ìƒì„± ì„±ê³µ: {operation.id}")
                    return {
                        "success": True,
                        "data": {"node_id": operation.id},
                        "operation_id": operation.id
                    }
                else:
                    return {
                        "success": False,
                        "errors": ["ë…¸ë“œ ìƒì„± ì‹¤íŒ¨"],
                        "operation_id": operation.id
                    }
                    
        except Exception as e:
            logger.error(f"âŒ ë…¸ë“œ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "errors": [str(e)],
                "operation_id": operation.id
            }
    
    async def _execute_update_operation(self, operation: GraphOperation) -> Dict[str, Any]:
        """ë…¸ë“œ ì—…ë°ì´íŠ¸ ì‘ì—… ì‹¤í–‰"""
        try:
            with self.driver.session() as session:
                # ë…¸ë“œ ì—…ë°ì´íŠ¸ ì¿¼ë¦¬
                query = f"""
                MATCH (n:{':'.join(operation.labels)} {{id: $id}})
                SET n += $properties
                RETURN n
                """
                
                result = session.run(query, {
                    "id": operation.target_id,
                    "properties": operation.properties
                })
                node = result.single()
                
                if node:
                    logger.info(f"âœ… ë…¸ë“œ ì—…ë°ì´íŠ¸ ì„±ê³µ: {operation.id}")
                    return {
                        "success": True,
                        "data": {"node_id": operation.target_id},
                        "operation_id": operation.id
                    }
                else:
                    return {
                        "success": False,
                        "errors": ["ë…¸ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ"],
                        "operation_id": operation.id
                    }
                    
        except Exception as e:
            logger.error(f"âŒ ë…¸ë“œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "errors": [str(e)],
                "operation_id": operation.id
            }
    
    async def _execute_delete_operation(self, operation: GraphOperation) -> Dict[str, Any]:
        """ë…¸ë“œ ì‚­ì œ ì‘ì—… ì‹¤í–‰"""
        try:
            with self.driver.session() as session:
                # ë…¸ë“œ ì‚­ì œ ì¿¼ë¦¬
                query = f"""
                MATCH (n:{':'.join(operation.labels)} {{id: $id}})
                DETACH DELETE n
                RETURN count(n) as deleted
                """
                
                result = session.run(query, {"id": operation.target_id})
                deleted = result.single()
                
                if deleted and deleted["deleted"] > 0:
                    logger.info(f"âœ… ë…¸ë“œ ì‚­ì œ ì„±ê³µ: {operation.id}")
                    return {
                        "success": True,
                        "data": {"deleted": True},
                        "operation_id": operation.id
                    }
                else:
                    return {
                        "success": False,
                        "errors": ["ë…¸ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ"],
                        "operation_id": operation.id
                    }
                    
        except Exception as e:
            logger.error(f"âŒ ë…¸ë“œ ì‚­ì œ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "errors": [str(e)],
                "operation_id": operation.id
            }
    
    async def _execute_create_relationship_operation(self, operation: GraphOperation) -> Dict[str, Any]:
        """ê´€ê³„ ìƒì„± ì‘ì—… ì‹¤í–‰"""
        try:
            with self.driver.session() as session:
                # ê´€ê³„ ìƒì„± ì¿¼ë¦¬
                query = f"""
                MATCH (a), (b)
                WHERE a.id = $start_id AND b.id = $end_id
                CREATE (a)-[r:{operation.relationship_type} {{
                    {', '.join([f'{k}: ${k}' for k in operation.properties.keys()])}
                }}]->(b)
                RETURN r
                """
                
                result = session.run(query, {
                    "start_id": operation.start_node_id,
                    "end_id": operation.end_node_id,
                    **operation.properties
                })
                relationship = result.single()
                
                if relationship:
                    logger.info(f"âœ… ê´€ê³„ ìƒì„± ì„±ê³µ: {operation.id}")
                    return {
                        "success": True,
                        "data": {"relationship_id": operation.id},
                        "operation_id": operation.id
                    }
                else:
                    return {
                        "success": False,
                        "errors": ["ë…¸ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ"],
                        "operation_id": operation.id
                    }
                    
        except Exception as e:
            logger.error(f"âŒ ê´€ê³„ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "errors": [str(e)],
                "operation_id": operation.id
            }
    
    async def _execute_merge_node_operation(self, operation: GraphOperation) -> Dict[str, Any]:
        """ë…¸ë“œ ë³‘í•© ì‘ì—… ì‹¤í–‰"""
        try:
            with self.driver.session() as session:
                # ë…¸ë“œ ë³‘í•© ì¿¼ë¦¬
                query = f"""
                MERGE (n:{':'.join(operation.labels)} {{id: $id}})
                SET n += $properties
                RETURN n
                """
                
                result = session.run(query, {
                    "id": operation.target_id,
                    "properties": operation.properties
                })
                node = result.single()
                
                if node:
                    logger.info(f"âœ… ë…¸ë“œ ë³‘í•© ì„±ê³µ: {operation.id}")
                    return {
                        "success": True,
                        "data": {"node_id": operation.target_id},
                        "operation_id": operation.id
                    }
                else:
                    return {
                        "success": False,
                        "errors": ["ë…¸ë“œ ë³‘í•© ì‹¤íŒ¨"],
                        "operation_id": operation.id
                    }
                    
        except Exception as e:
            logger.error(f"âŒ ë…¸ë“œ ë³‘í•© ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "errors": [str(e)],
                "operation_id": operation.id
            }
    
    def _initialize_schema(self):
        """Neo4j ìŠ¤í‚¤ë§ˆ ì´ˆê¸°í™”"""
        try:
            with self.driver.session() as session:
                # ë…¸ë“œ ì œì•½ ì¡°ê±´ ìƒì„±
                self._create_node_constraints(session)
                
                # ê´€ê³„ ì œì•½ ì¡°ê±´ ìƒì„±
                self._create_relationship_constraints(session)
                
                # ì¸ë±ìŠ¤ ìƒì„±
                self._create_indexes(session)
                
                # ê¸°ë³¸ ë°ì´í„° êµ¬ì¡° ìƒì„±
                self._create_base_structure(session)
                
            logger.info("âœ… Neo4j ìŠ¤í‚¤ë§ˆ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ìŠ¤í‚¤ë§ˆ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def _create_node_constraints(self, session):
        """ë…¸ë“œ ì œì•½ ì¡°ê±´ ìƒì„±"""
        constraints = [
            # User ë…¸ë“œ ì œì•½ ì¡°ê±´
            "CREATE CONSTRAINT user_id_unique IF NOT EXISTS FOR (u:User) REQUIRE u.id IS UNIQUE",
            "CREATE CONSTRAINT user_email_unique IF NOT EXISTS FOR (u:User) REQUIRE u.email IS UNIQUE",
            
            # Document ë…¸ë“œ ì œì•½ ì¡°ê±´
            "CREATE CONSTRAINT document_id_unique IF NOT EXISTS FOR (d:Document) REQUIRE d.id IS UNIQUE",
            "CREATE CONSTRAINT document_path_unique IF NOT EXISTS FOR (d:Document) REQUIRE d.path IS UNIQUE",
            
            # Tag ë…¸ë“œ ì œì•½ ì¡°ê±´
            "CREATE CONSTRAINT tag_name_unique IF NOT EXISTS FOR (t:Tag) REQUIRE t.name IS UNIQUE",
            
            # Concept ë…¸ë“œ ì œì•½ ì¡°ê±´
            "CREATE CONSTRAINT concept_id_unique IF NOT EXISTS FOR (c:Concept) REQUIRE c.id IS UNIQUE",
            
            # Project ë…¸ë“œ ì œì•½ ì¡°ê±´
            "CREATE CONSTRAINT project_id_unique IF NOT EXISTS FOR (p:Project) REQUIRE p.id IS UNIQUE"
        ]
        
        for constraint in constraints:
            try:
                session.run(constraint)
                logger.debug(f"ì œì•½ ì¡°ê±´ ìƒì„±: {constraint}")
            except Exception as e:
                logger.warning(f"ì œì•½ ì¡°ê±´ ìƒì„± ì‹¤íŒ¨: {constraint} - {e}")
    
    def _create_relationship_constraints(self, session):
        """ê´€ê³„ ì œì•½ ì¡°ê±´ ìƒì„±"""
        constraints = [
            # ê´€ê³„ íƒ€ì… ì œì•½ ì¡°ê±´
            "CREATE CONSTRAINT relationship_type_exists IF NOT EXISTS FOR ()-[r]-() REQUIRE r.type IS NOT NULL",
            
            # ê´€ê³„ ì†ì„± ì œì•½ ì¡°ê±´
            "CREATE CONSTRAINT relationship_timestamp_exists IF NOT EXISTS FOR ()-[r]-() REQUIRE r.timestamp IS NOT NULL"
        ]
        
        for constraint in constraints:
            try:
                session.run(constraint)
                logger.debug(f"ê´€ê³„ ì œì•½ ì¡°ê±´ ìƒì„±: {constraint}")
            except Exception as e:
                logger.warning(f"ê´€ê³„ ì œì•½ ì¡°ê±´ ìƒì„± ì‹¤íŒ¨: {constraint} - {e}")
    
    def _create_indexes(self, session):
        """ì¸ë±ìŠ¤ ìƒì„±"""
        indexes = [
            # User ì¸ë±ìŠ¤
            "CREATE INDEX user_name_index IF NOT EXISTS FOR (u:User) ON (u.name)",
            "CREATE INDEX user_created_at_index IF NOT EXISTS FOR (u:User) ON (u.created_at)",
            
            # Document ì¸ë±ìŠ¤
            "CREATE INDEX document_type_index IF NOT EXISTS FOR (d:Document) ON (d.type)",
            "CREATE INDEX document_created_at_index IF NOT EXISTS FOR (d:Document) ON (d.created_at)",
            "CREATE INDEX document_modified_at_index IF NOT EXISTS FOR (d:Document) ON (d.modified_at)",
            
            # Tag ì¸ë±ìŠ¤
            "CREATE INDEX tag_category_index IF NOT EXISTS FOR (t:Tag) ON (t.category)",
            
            # Concept ì¸ë±ìŠ¤
            "CREATE INDEX concept_name_index IF NOT EXISTS FOR (c:Concept) ON (c.name)",
            "CREATE INDEX concept_category_index IF NOT EXISTS FOR (c:Concept) ON (c.category)",
            
            # ê´€ê³„ ì¸ë±ìŠ¤
            "CREATE INDEX relationship_timestamp_index IF NOT EXISTS FOR ()-[r]-() ON (r.timestamp)",
            "CREATE INDEX relationship_weight_index IF NOT EXISTS FOR ()-[r]-() ON (r.weight)"
        ]
        
        for index in indexes:
            try:
                session.run(index)
                logger.debug(f"ì¸ë±ìŠ¤ ìƒì„±: {index}")
            except Exception as e:
                logger.warning(f"ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {index} - {e}")
    
    def _create_base_structure(self, session):
        """ê¸°ë³¸ ë°ì´í„° êµ¬ì¡° ìƒì„±"""
        try:
            # ì‹œìŠ¤í…œ ì‚¬ìš©ì ìƒì„±
            system_user_query = """
            MERGE (u:User {id: 'system', email: 'system@argo.local'})
            SET u.name = 'ARGO System',
                u.role = 'system',
                u.created_at = datetime(),
                u.is_active = true
            RETURN u
            """
            session.run(system_user_query)
            
            # ê¸°ë³¸ íƒœê·¸ ì¹´í…Œê³ ë¦¬ ìƒì„±
            tag_categories = [
                'documentation', 'code', 'design', 'meeting_notes',
                'planning', 'research', 'personal', 'reference'
            ]
            
            for category in tag_categories:
                tag_query = """
                MERGE (t:Tag {name: $category})
                SET t.category = 'content_type',
                    t.created_at = datetime(),
                    t.is_system = true
                RETURN t
                """
                session.run(tag_query, category=category)
            
            # ê¸°ë³¸ í”„ë¡œì íŠ¸ ìƒì„±
            project_query = """
            MERGE (p:Project {id: 'default', name: 'Default Project'})
            SET p.description = 'Default ARGO project',
                p.created_at = datetime(),
                p.is_active = true
            RETURN p
            """
            session.run(project_query)
            
            logger.info("âœ… ê¸°ë³¸ ë°ì´í„° êµ¬ì¡° ìƒì„± ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ê¸°ë³¸ ë°ì´í„° êµ¬ì¡° ìƒì„± ì‹¤íŒ¨: {e}")
    
    async def execute_graph_operation(self, operation: GraphOperation) -> Dict[str, Any]:
        """ê·¸ë˜í”„ ì‘ì—… ì‹¤í–‰ (MockNeo4j í˜¸í™˜)"""
        try:
            logger.info(f"ê·¸ë˜í”„ ì‘ì—… ì‹¤í–‰ ì‹œì‘: {operation.operation_type.value}")
            
            # MockNeo4jë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ì ‘ ì‘ì—… ì‹¤í–‰
            if operation.operation_type == GraphOperationType.CREATE_NODE:
                result = await self._execute_create_operation(operation)
            elif operation.operation_type == GraphOperationType.UPDATE_NODE:
                result = await self._execute_update_operation(operation)
            elif operation.operation_type == GraphOperationType.DELETE_NODE:
                result = await self._execute_delete_operation(operation)
            elif operation.operation_type == GraphOperationType.CREATE_RELATIONSHIP:
                result = await self._execute_create_relationship_operation(operation)
            elif operation.operation_type == GraphOperationType.MERGE_NODE:
                result = await self._execute_merge_node_operation(operation)
            else:
                result = {"success": False, "errors": [f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‘ì—… íƒ€ì…: {operation.operation_type.value}"]}
            
            # Redisì— ê²°ê³¼ ì €ì¥
            if result.get("success"):
                result_key = f"graph_operation_result:{operation.id}"
                self.redis_client.setex(
                    result_key,
                    3600,  # 1ì‹œê°„ TTL
                    json.dumps({
                        "success": True,
                        "result": result.get("data", []),
                        "timestamp": datetime.utcnow().isoformat()
                    })
                )
            
            logger.info(f"âœ… ê·¸ë˜í”„ ì‘ì—… ì‹¤í–‰ ì™„ë£Œ: {operation.operation_type.value}")
            return result
            
        except Exception as e:
            logger.error(f"ê·¸ë˜í”„ ì‘ì—… ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "errors": [str(e)],
                "operation_id": operation.id
            }
    
    async def _validate_operation(self, state: Dict) -> Dict:
        """ì‘ì—… ê²€ì¦ (LangGraph ë…¸ë“œ)"""
        operation = state["current_operation"]
        validation_results = []
        
        try:
            # ê¸°ë³¸ ê²€ì¦
            if not operation.id:
                validation_results.append("ì‘ì—… IDê°€ ì—†ìŠµë‹ˆë‹¤")
            
            if not operation.operation_type:
                validation_results.append("ì‘ì—… íƒ€ì…ì´ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
            # ë…¸ë“œ ìƒì„± ê²€ì¦
            if operation.operation_type == GraphOperationType.CREATE_NODE:
                if not operation.labels:
                    validation_results.append("ë…¸ë“œ ë¼ë²¨ì´ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                
                if not operation.properties:
                    validation_results.append("ë…¸ë“œ ì†ì„±ì´ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
            # ê´€ê³„ ìƒì„± ê²€ì¦
            elif operation.operation_type == GraphOperationType.CREATE_RELATIONSHIP:
                if not operation.relationship_type:
                    validation_results.append("ê´€ê³„ íƒ€ì…ì´ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                
                if not operation.start_node_id or not operation.end_node_id:
                    validation_results.append("ì‹œì‘/ë ë…¸ë“œ IDê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
            # ì œì•½ ì¡°ê±´ ê²€ì¦
            for constraint in operation.constraints:
                if not self._validate_constraint(operation, constraint):
                    validation_results.append(f"ì œì•½ ì¡°ê±´ ê²€ì¦ ì‹¤íŒ¨: {constraint}")
            
            # ê²€ì¦ ê·œì¹™ ê²€ì¦
            for rule in operation.validation_rules:
                if not self._validate_rule(operation, rule):
                    validation_results.append(f"ê²€ì¦ ê·œì¹™ ì‹¤íŒ¨: {rule}")
            
            if validation_results:
                state["validation_results"] = validation_results
                state["errors"].append("ê²€ì¦ ì‹¤íŒ¨")
                return state
            
            state["validation_results"] = ["ê²€ì¦ í†µê³¼"]
            return state
            
        except Exception as e:
            state["errors"].append(f"ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return state
    
    async def _execute_operation(self, state: Dict) -> Dict:
        """ì‘ì—… ì‹¤í–‰ (LangGraph ë…¸ë“œ)"""
        operation = state["current_operation"]
        execution_results = []
        
        try:
            if operation.operation_type == GraphOperationType.CREATE_NODE:
                result = await self._create_node(operation)
                execution_results.append(result)
                
            elif operation.operation_type == GraphOperationType.UPDATE_NODE:
                result = await self._update_node(operation)
                execution_results.append(result)
                
            elif operation.operation_type == GraphOperationType.DELETE_NODE:
                result = await self._delete_node(operation)
                execution_results.append(result)
                
            elif operation.operation_type == GraphOperationType.CREATE_RELATIONSHIP:
                result = await self._create_relationship(operation)
                execution_results.append(result)
                
            elif operation.operation_type == GraphOperationType.MERGE_NODE:
                result = await self._merge_node(operation)
                execution_results.append(result)
                
            elif operation.operation_type == GraphOperationType.BATCH_OPERATION:
                result = await self._execute_batch_operation(operation)
                execution_results.append(result)
            
            state["execution_results"] = execution_results
            return state
            
        except Exception as e:
            state["errors"].append(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return state
    
    async def _create_node(self, operation: GraphOperation) -> Dict[str, Any]:
        """ë…¸ë“œ ìƒì„±"""
        try:
            with self.driver.session() as session:
                # ë¼ë²¨ ë¬¸ìì—´ ìƒì„±
                label_str = ':'.join(operation.labels) if operation.labels else ''
                
                # ì†ì„±ì— íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
                properties = operation.properties.copy()
                properties.update({
                    'id': operation.target_id or str(uuid.uuid4()),
                    'created_at': datetime.utcnow().isoformat(),
                    'modified_at': datetime.utcnow().isoformat()
                })
                
                # ë…¸ë“œ ìƒì„± ì¿¼ë¦¬
                query = f"""
                CREATE (n{':' + label_str if label_str else ''} $properties)
                RETURN n
                """
                
                result = session.run(query, properties=properties)
                node = result.single()["n"]
                
                logger.info(f"âœ… ë…¸ë“œ ìƒì„± ì™„ë£Œ: {node.get('id')}")
                
                return {
                    "operation": "create_node",
                    "node_id": node.get('id'),
                    "labels": list(node.labels),
                    "properties": dict(node),
                    "success": True
                }
                
        except Exception as e:
            logger.error(f"âŒ ë…¸ë“œ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "operation": "create_node",
                "success": False,
                "error": str(e)
            }
    
    async def _update_node(self, operation: GraphOperation) -> Dict[str, Any]:
        """ë…¸ë“œ ì—…ë°ì´íŠ¸"""
        try:
            with self.driver.session() as session:
                # ê¸°ì¡´ ë…¸ë“œ ì¡°íšŒ
                query = """
                MATCH (n) WHERE n.id = $node_id
                RETURN n
                """
                
                result = session.run(query, node_id=operation.target_id)
                existing_node = result.single()
                
                if not existing_node:
                    return {
                        "operation": "update_node",
                        "success": False,
                        "error": "ë…¸ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
                    }
                
                # ì†ì„± ì—…ë°ì´íŠ¸
                properties = operation.properties.copy()
                properties['modified_at'] = datetime.utcnow().isoformat()
                
                update_query = """
                MATCH (n) WHERE n.id = $node_id
                SET n += $properties
                RETURN n
                """
                
                result = session.run(update_query, 
                                  node_id=operation.target_id, 
                                  properties=properties)
                
                updated_node = result.single()["n"]
                
                logger.info(f"âœ… ë…¸ë“œ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {operation.target_id}")
                
                return {
                    "operation": "update_node",
                    "node_id": operation.target_id,
                    "properties": dict(updated_node),
                    "success": True
                }
                
        except Exception as e:
            logger.error(f"âŒ ë…¸ë“œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return {
                "operation": "update_node",
                "success": False,
                "error": str(e)
            }
    
    async def _delete_node(self, operation: GraphOperation) -> Dict[str, Any]:
        """ë…¸ë“œ ì‚­ì œ"""
        try:
            with self.driver.session() as session:
                # ë…¸ë“œì™€ ê´€ë ¨ëœ ëª¨ë“  ê´€ê³„ ì‚­ì œ
                query = """
                MATCH (n) WHERE n.id = $node_id
                OPTIONAL MATCH (n)-[r]-()
                DELETE r, n
                RETURN count(n) as deleted_count
                """
                
                result = session.run(query, node_id=operation.target_id)
                deleted_count = result.single()["deleted_count"]
                
                logger.info(f"âœ… ë…¸ë“œ ì‚­ì œ ì™„ë£Œ: {operation.target_id}")
                
                return {
                    "operation": "delete_node",
                    "node_id": operation.target_id,
                    "deleted_count": deleted_count,
                    "success": True
                }
                
        except Exception as e:
            logger.error(f"âŒ ë…¸ë“œ ì‚­ì œ ì‹¤íŒ¨: {e}")
            return {
                "operation": "delete_node",
                "success": False,
                "error": str(e)
            }
    
    async def _create_relationship(self, operation: GraphOperation) -> Dict[str, Any]:
        """ê´€ê³„ ìƒì„±"""
        try:
            with self.driver.session() as session:
                # ì‹œì‘/ë ë…¸ë“œ ì¡´ì¬ í™•ì¸
                start_query = "MATCH (n) WHERE n.id = $node_id RETURN n"
                end_query = "MATCH (n) WHERE n.id = $node_id RETURN n"
                
                start_result = session.run(start_query, node_id=operation.start_node_id)
                end_result = session.run(end_query, node_id=operation.end_node_id)
                
                if not start_result.single() or not end_result.single():
                    return {
                        "operation": "create_relationship",
                        "success": False,
                        "error": "ì‹œì‘ ë˜ëŠ” ë ë…¸ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
                    }
                
                # ê´€ê³„ ì†ì„±ì— íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
                properties = operation.properties.copy()
                properties.update({
                    'created_at': datetime.utcnow().isoformat(),
                    'weight': properties.get('weight', 1.0)
                })
                
                # ê´€ê³„ ìƒì„±
                rel_query = """
                MATCH (a), (b) 
                WHERE a.id = $start_id AND b.id = $end_id
                CREATE (a)-[r:$rel_type $properties]->(b)
                RETURN r
                """
                
                result = session.run(rel_query,
                                  start_id=operation.start_node_id,
                                  end_id=operation.end_node_id,
                                  rel_type=operation.relationship_type,
                                  properties=properties)
                
                relationship = result.single()["r"]
                
                logger.info(f"âœ… ê´€ê³„ ìƒì„± ì™„ë£Œ: {operation.start_node_id} -> {operation.end_node_id}")
                
                return {
                    "operation": "create_relationship",
                    "relationship_id": id(relationship),
                    "start_node": operation.start_node_id,
                    "end_node": operation.end_node_id,
                    "type": operation.relationship_type,
                    "properties": dict(relationship),
                    "success": True
                }
                
        except Exception as e:
            logger.error(f"âŒ ê´€ê³„ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "operation": "create_relationship",
                "success": False,
                "error": str(e)
            }
    
    async def _merge_node(self, operation: GraphOperation) -> Dict[str, Any]:
        """ë…¸ë“œ ë³‘í•© (MERGE)"""
        try:
            with self.driver.session() as session:
                # ë¼ë²¨ ë¬¸ìì—´ ìƒì„±
                label_str = ':'.join(operation.labels) if operation.labels else ''
                
                # ì†ì„±ì— íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
                properties = operation.properties.copy()
                properties.update({
                    'id': operation.target_id or str(uuid.uuid4()),
                    'modified_at': datetime.utcnow().isoformat()
                })
                
                # MERGE ì¿¼ë¦¬ (ê¸°ì¡´ ë…¸ë“œê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸, ì—†ìœ¼ë©´ ìƒì„±)
                merge_query = f"""
                MERGE (n{':' + label_str if label_str else ''} {{id: $id}})
                ON CREATE SET n += $properties, n.created_at = datetime()
                ON MATCH SET n += $properties
                RETURN n
                """
                
                result = session.run(merge_query, 
                                  id=properties['id'],
                                  properties=properties)
                
                node = result.single()["n"]
                
                logger.info(f"âœ… ë…¸ë“œ ë³‘í•© ì™„ë£Œ: {node.get('id')}")
                
                return {
                    "operation": "merge_node",
                    "node_id": node.get('id'),
                    "labels": list(node.labels),
                    "properties": dict(node),
                    "success": True
                }
                
        except Exception as e:
            logger.error(f"âŒ ë…¸ë“œ ë³‘í•© ì‹¤íŒ¨: {e}")
            return {
                "operation": "merge_node",
                "success": False,
                "error": str(e)
            }
    
    async def _execute_batch_operation(self, operation: GraphOperation) -> Dict[str, Any]:
        """ë°°ì¹˜ ì‘ì—… ì‹¤í–‰"""
        try:
            batch_data = operation.properties.get('batch_data', [])
            if not batch_data:
                return {
                    "operation": "batch_operation",
                    "success": False,
                    "error": "ë°°ì¹˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"
                }
            
            results = []
            with self.driver.session() as session:
                with session.begin_transaction() as tx:
                    for item in batch_data:
                        try:
                            if item['type'] == 'create_node':
                                result = await self._create_node_in_transaction(tx, item)
                            elif item['type'] == 'create_relationship':
                                result = await self._create_relationship_in_transaction(tx, item)
                            else:
                                result = {"success": False, "error": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‘ì—… íƒ€ì…: {item['type']}"}
                            
                            results.append(result)
                            
                        except Exception as e:
                            results.append({"success": False, "error": str(e)})
                    
                    # ëª¨ë“  ì‘ì—…ì´ ì„±ê³µí•˜ë©´ ì»¤ë°‹
                    if all(r.get('success', False) for r in results):
                        tx.commit()
                        logger.info(f"âœ… ë°°ì¹˜ ì‘ì—… ì™„ë£Œ: {len(results)}ê°œ ì‘ì—…")
                    else:
                        tx.rollback()
                        logger.error(f"âŒ ë°°ì¹˜ ì‘ì—… ì‹¤íŒ¨, ë¡¤ë°±ë¨")
            
            logger.info(f"âœ… ë°°ì¹˜ ì‘ì—… ì™„ë£Œ: {len(batch_data)}ê°œ ì‘ì—…")
            
            return {
                "operation": "batch_operation",
                "results": results,
                "total_count": len(batch_data),
                "success_count": sum(1 for r in results if r.get('success', False)),
                "success": True
            }
            
        except Exception as e:
            logger.error(f"âŒ ë°°ì¹˜ ì‘ì—… ì‹¤íŒ¨: {e}")
            return {
                "operation": "batch_operation",
                "success": False,
                "error": str(e)
            }
    
    async def _create_node_in_transaction(self, tx, item: Dict) -> Dict[str, Any]:
        """íŠ¸ëœì­ì…˜ ë‚´ì—ì„œ ë…¸ë“œ ìƒì„±"""
        labels = item.get('labels', [])
        properties = item.get('properties', {})
        
        label_str = ':'.join(labels) if labels else ''
        properties.update({
            'id': str(uuid.uuid4()),
            'created_at': datetime.utcnow().isoformat(),
            'modified_at': datetime.utcnow().isoformat()
        })
        
        query = f"CREATE (n{':' + label_str if label_str else ''} $properties) RETURN n"
        result = tx.run(query, properties=properties)
        node = result.single()["n"]
        
        return {
            "type": "create_node",
            "node_id": node.get('id'),
            "success": True
        }
    
    async def _create_relationship_in_transaction(self, tx, item: Dict) -> Dict[str, Any]:
        """íŠ¸ëœì­ì…˜ ë‚´ì—ì„œ ê´€ê³„ ìƒì„±"""
        start_id = item.get('start_node_id')
        end_id = item.get('end_node_id')
        rel_type = item.get('relationship_type')
        properties = item.get('properties', {})
        
        properties.update({
            'created_at': datetime.utcnow().isoformat(),
            'weight': properties.get('weight', 1.0)
        })
        
        query = """
        MATCH (a), (b) 
        WHERE a.id = $start_id AND b.id = $end_id
        CREATE (a)-[r:$rel_type $properties]->(b)
        RETURN r
        """
        
        result = tx.run(query,
                      start_id=start_id,
                      end_id=end_id,
                      rel_type=rel_type,
                      properties=properties)
        
        return {
            "type": "create_relationship",
            "success": True
        }
    
    def _validate_constraint(self, operation: GraphOperation, constraint: str) -> bool:
        """ì œì•½ ì¡°ê±´ ê²€ì¦"""
        try:
            # ê°„ë‹¨í•œ ì œì•½ ì¡°ê±´ ê²€ì¦ ë¡œì§
            if constraint == "unique_id":
                return operation.target_id is not None
            elif constraint == "required_properties":
                required_props = ['name', 'type']
                return all(prop in operation.properties for prop in required_props)
            elif constraint == "valid_labels":
                valid_labels = ['User', 'Document', 'Tag', 'Concept', 'Project']
                return all(label in valid_labels for label in operation.labels)
            
            return True
            
        except Exception as e:
            logger.error(f"ì œì•½ ì¡°ê±´ ê²€ì¦ ì‹¤íŒ¨: {constraint} - {e}")
            return False
    
    def _validate_rule(self, operation: GraphOperation, rule: str) -> bool:
        """ê²€ì¦ ê·œì¹™ ê²€ì¦"""
        try:
            # ê°„ë‹¨í•œ ê²€ì¦ ê·œì¹™ ë¡œì§
            if rule == "max_properties":
                max_props = 20
                return len(operation.properties) <= max_props
            elif rule == "valid_property_types":
                valid_types = [str, int, float, bool]
                return all(isinstance(v, tuple(valid_types)) for v in operation.properties.values())
            
            return True
            
        except Exception as e:
            logger.error(f"ê²€ì¦ ê·œì¹™ ì‹¤íŒ¨: {rule} - {e}")
            return False
    
    async def _update_metrics(self, state: Dict) -> Dict:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸ (LangGraph ë…¸ë“œ)"""
        try:
            operation = state["current_operation"]
            
            # ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
            start_time = datetime.utcnow()
            execution_time = (start_time - operation.timestamp).total_seconds()
            
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì €ì¥
            self.performance_metrics[operation.id] = {
                "execution_time": execution_time,
                "operation_type": operation.operation_type.value,
                "timestamp": start_time.isoformat()
            }
            
            state["performance_metrics"] = self.performance_metrics
            return state
            
        except Exception as e:
            state["errors"].append(f"ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
            return state
    
    async def _handle_errors(self, state: Dict) -> Dict:
        """ì—ëŸ¬ ì²˜ë¦¬ (LangGraph ë…¸ë“œ)"""
        try:
            operation = state["current_operation"]
            
            # ì‹¤íŒ¨í•œ ì‘ì—…ì„ ì¬ì‹œë„ íì— ì¶”ê°€
            if operation.id not in [op.id for op in self.failed_operations]:
                self.failed_operations.append(operation)
                
                # Redisì— ì‹¤íŒ¨ ì •ë³´ ì €ì¥
                error_key = f"graph_operation_error:{operation.id}"
                self.redis_client.setex(
                    error_key,
                    7200,  # 2ì‹œê°„ TTL
                    json.dumps({
                        "operation_id": operation.id,
                        "errors": state.get("errors", []),
                        "timestamp": datetime.utcnow().isoformat()
                    })
                )
            
            logger.error(f"ì‘ì—… ì‹¤íŒ¨: {operation.id} - {state.get('errors', [])}")
            return state
            
        except Exception as e:
            state["errors"].append(f"ì—ëŸ¬ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            return state
    
    async def execute_cypher_query(self, query: str, parameters: Dict = None) -> Dict[str, Any]:
        """Cypher ì¿¼ë¦¬ ì‹¤í–‰"""
        try:
            start_time = datetime.utcnow()
            
            with self.driver.session() as session:
                result = session.run(query, parameters or {})
                
                # ê²°ê³¼ ì²˜ë¦¬
                records = []
                for record in result:
                    try:
                        # MockNeo4j ê²°ê³¼ë¥¼ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
                        if hasattr(record, 'data'):
                            records.append(record.data)
                        else:
                            records.append(dict(record))
                    except Exception as e:
                        logger.warning(f"ë ˆì½”ë“œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                        # ê¸°ë³¸ê°’ìœ¼ë¡œ ì²˜ë¦¬
                        records.append({"raw_record": str(record)})
                
                execution_time = (datetime.utcnow() - start_time).total_seconds()
                
                logger.info(f"âœ… Cypher ì¿¼ë¦¬ ì‹¤í–‰ ì™„ë£Œ: {execution_time:.3f}ì´ˆ")
                
                return {
                    "success": True,
                    "records": records,
                    "count": len(records),
                    "execution_time": execution_time
                }
                
        except Exception as e:
            logger.error(f"âŒ Cypher ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "query": query
            }
    
    def get_performance_metrics(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
        return {
            "performance_metrics": self.performance_metrics,
            "operation_queue_size": len(self.operation_queue),
            "failed_operations_count": len(self.failed_operations)
        }
    
    async def cleanup_failed_operations(self) -> int:
        """ì‹¤íŒ¨í•œ ì‘ì—… ì •ë¦¬"""
        cleaned_count = 0
        
        for operation in self.failed_operations[:]:
            # 24ì‹œê°„ ì´ìƒ ëœ ì‹¤íŒ¨ ì‘ì—… ì œê±°
            if datetime.utcnow() - operation.timestamp > timedelta(hours=24):
                self.failed_operations.remove(operation)
                cleaned_count += 1
                
                # Redisì—ì„œë„ ì œê±°
                error_key = f"graph_operation_error:{operation.id}"
                self.redis_client.delete(error_key)
        
        if cleaned_count > 0:
            logger.info(f"ì‹¤íŒ¨í•œ ì‘ì—… ì •ë¦¬ ì™„ë£Œ: {cleaned_count}ê°œ")
        
        return cleaned_count
    
    async def shutdown(self):
        """ì •ìƒ ì¢…ë£Œ"""
        try:
            # ì‹¤íŒ¨í•œ ì‘ì—… ì •ë¦¬
            await self.cleanup_failed_operations()
            
            # Neo4j ì—°ê²° ì¢…ë£Œ
            if self.driver:
                self.driver.close()
            
            logger.info("Neo4jLangGraphManager ì •ìƒ ì¢…ë£Œ")
            
        except Exception as e:
            logger.error(f"ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜: {e}")

# ì‚¬ìš© ì˜ˆì‹œ
async def main():
    # ì„¤ì •
    neo4j_config = {
        'uri': 'bolt://localhost:7687',
        'username': 'neo4j',
        'password': 'password'
    }
    
    redis_config = {
        'host': 'localhost',
        'port': 6379,
        'db': 0
    }
    
    # ë§¤ë‹ˆì € ì´ˆê¸°í™”
    manager = Neo4jLangGraphManager(neo4j_config, redis_config)
    
    try:
        # ë…¸ë“œ ìƒì„± ì‘ì—…
        create_node_op = GraphOperation(
            id="op_001",
            operation_type=GraphOperationType.CREATE_NODE,
            target_type="node",
            labels=["User"],
            properties={
                "name": "Test User",
                "email": "test@example.com",
                "role": "developer"
            }
        )
        
        # ì‘ì—… ì‹¤í–‰
        result = await manager.execute_graph_operation(create_node_op)
        print(f"ì‘ì—… ê²°ê³¼: {json.dumps(result, indent=2, default=str)}")
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ
        metrics = manager.get_performance_metrics()
        print(f"ì„±ëŠ¥ ë©”íŠ¸ë¦­: {json.dumps(metrics, indent=2, default=str)}")
        
    finally:
        await manager.shutdown()

if __name__ == "__main__":
    asyncio.run(main())
